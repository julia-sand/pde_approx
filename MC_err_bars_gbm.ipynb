{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mc_errs_d2_t05_gbm.csv\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "using Distributions;\n",
    "using Random;\n",
    "using DataFrames;\n",
    "using CSV;\n",
    "using Statistics;\n",
    "using LinearAlgebra;\n",
    "using Flux;\n",
    "using Flux: params, \n",
    "            Dense, \n",
    "            Chain, \n",
    "            glorot_normal, \n",
    "            normalise, \n",
    "            Optimiser,\n",
    "            train!;\n",
    "\n",
    "###MC errors and bars for d = 2\n",
    "\n",
    "function mc_err_bars(T,file_name)\n",
    "    df_row_titles = DataFrame(x1= \"x1\",x2 =\"x2\"\n",
    "        ,y_vals = \"y_vals\",mc_vals=\"mc_vals\",sd_err=\"sd_errs\")\n",
    "    \n",
    "    CSV.write(file_name, df_row_titles, append = true);\n",
    "\n",
    "    d = 2\n",
    "    \n",
    "    r = Float16(0.05);\n",
    "    K = Int(100); #strike\n",
    "    mu = Float16(-0.05); \n",
    "    a = 90\n",
    "    b = 110\n",
    "    N = 1\n",
    "\n",
    "    time_grid = LinRange(1/d, 1, d); \n",
    "    sigma = 0.1 .+ 0.5 .* time_grid;\n",
    "    mc_samples = 1000000\n",
    "    batch_samples = 8000\n",
    "    batch_test = 400\n",
    "    \n",
    "    initial_sampler = Uniform(90,110);\n",
    "\n",
    "    train_steps = 400000\n",
    "    learning_rate = 0.001\n",
    "    learn_rate_decrease = 100000\n",
    "    \n",
    "    #standard normalisation function \n",
    "    function norm_ab(y)\n",
    "        mid_point = (a + b) / 2\n",
    "        y_norm(y) = (y .- mid_point) ./ (b-a)\n",
    "        return mapslices(y_norm,y;dims =1)\n",
    "    end\n",
    "    \n",
    "    #fixed samples\n",
    "    X_test_vals = rand(initial_sampler,(d,batch_test))\n",
    "    \n",
    "    function x_sde(X::Array,batch) #discretisation of SDE \n",
    "        #how_many_samples = length(X)\n",
    "        for _ in 1:N\n",
    "            #take appropriate samples from normal \n",
    "            eps = rand(Normal(0,1),(d, batch))\n",
    "            X = X .* (exp.((mu .- 0.5*sigma.^2)*(T/N) .+  sqrt(T/N).*( sigma .* eps)))\n",
    "        end\n",
    "        return X\n",
    "    end;    \n",
    "\n",
    "    function x_phi(x::Array) #function to use with FK expectation /initial conditions\n",
    "        phi_(x) = exp(-r*T) * max((maximum(x)-K),0)\n",
    "        mapslices(phi_, x; dims =1)\n",
    "    end;\n",
    "        \n",
    "    function generate_training_data(X_init,x_sde,x_phi)    \n",
    "        X_0 = Array(norm_ab(X_init))\n",
    "        X_sde = x_sde(X_init, batch_samples)\n",
    "        y_train = x_phi(X_sde)\n",
    "        return [(X_0,y_train)]\n",
    "    end\n",
    "\n",
    "    #define network layers\n",
    "    input = Dense(d, d + 10, tanh; \n",
    "                           bias = true, \n",
    "                           init = glorot_normal)\n",
    "\n",
    "    hidden = Dense(d + 10, d + 10, tanh;\n",
    "                            bias = true,\n",
    "                            init = glorot_normal)\n",
    "\n",
    "    #no activation on the last layer\n",
    "    output = Dense(d + 10,1,identity)\n",
    "\n",
    "    batch_norm_layer = BatchNorm(d + 10, identity;\n",
    "                                            initβ = zeros, \n",
    "                                            initγ = ones,\n",
    "                                            ϵ = 1e-6, \n",
    "                                            momentum = 0.9)\n",
    "    \n",
    "    #define network architecture\n",
    "    m = Chain(input,\n",
    "        #       batch_norm_layer,\n",
    "                hidden,\n",
    "        #        batch_norm_layer,\n",
    "        #        hidden,\n",
    "        #        batch_norm_layer,\n",
    "                output)\n",
    " \n",
    "    #loss function = \n",
    "    loss(u,v) = mean((m(u) - v).^2)\n",
    "    \n",
    "    ps = Flux.params(m)\n",
    "\n",
    "    opt = Optimiser(ExpDecay(learning_rate,0.01,learn_rate_decrease,1e-8),ADAM()) #optimiser\n",
    "\n",
    "    #set to train mode\n",
    "    trainmode!(m)\n",
    "    \n",
    "    #generate initial training data\n",
    "    X_init = rand(initial_sampler,(d,batch_samples))\n",
    "    data = generate_training_data(X_init,x_sde,x_phi)\n",
    "    \n",
    "    for k in 1:train_steps\n",
    "        \n",
    "        #generate new training data\n",
    "        X_init = rand(initial_sampler,(d,batch_samples))\n",
    "        data = generate_training_data(X_init,x_sde,x_phi)\n",
    "\n",
    "        #learning step\n",
    "        train!(loss,ps,data,opt)\n",
    "    end\n",
    "            \n",
    "    testmode!(m)\n",
    "    \n",
    "    y_vals = m(norm_ab(X_test_vals))\n",
    "    \n",
    "    #generate mc data\n",
    "    #add sd output here \n",
    "    function mc_sampler(X_test_vals)\n",
    "        x_mc_store = zeros((1,batch_test))\n",
    "        x_mc_sq = zeros((1,batch_test))\n",
    "        for _ in 1:mc_samples\n",
    "            sample_val = Array((x_phi(x_sde(X_test_vals,batch_test))))\n",
    "            x_mc_store += sample_val\n",
    "            x_mc_sq += sample_val.^2\n",
    "        end\n",
    "        phi_mc = x_mc_store ./ mc_samples;\n",
    "        phi_mc_sq = x_mc_sq ./ mc_samples;\n",
    "        phi_mc_mean_sq = phi_mc .^ 2;\n",
    "        sd_err = vec(sqrt.((phi_mc_sq .- phi_mc_mean_sq)./mc_samples));\n",
    "        mc_vals = vec(phi_mc);\n",
    "        \n",
    "        return mc_vals, sd_err\n",
    "    end \n",
    "    \n",
    "    mc_ans = mc_sampler(X_test_vals)\n",
    "    x1 = vec(X_test_vals[1,:])\n",
    "    x2 = vec(X_test_vals[2,:])\n",
    "    \n",
    "    df_row = DataFrame(x1= x1,x2 =x2\n",
    "        ,y_vals = vec(y_vals),mc_vals=vec(mc_ans[1]),sd_err=vec(mc_ans[2]))\n",
    "        \n",
    "    #write errs to file\n",
    "    CSV.write(file_name, df_row, append = true)\n",
    "    \n",
    "\n",
    "end\n",
    "\n",
    "mc_err_bars(1,\"mc_errs_d2_t1_gbm.csv\")\n",
    "mc_err_bars(0.5,\"mc_errs_d2_t05_gbm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
